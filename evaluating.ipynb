{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "* Create a Jupyter notebook.\n",
    "* Load the data (which you can find in MovieTweetings).\n",
    "* Use sklearn.decompose.nmf to create latent vectors for each movie.\n",
    "* Save the vectors in the following format (user userid, how should have content_id1 and content_id3 recommended, with the predicted ratings being value1 and value2 respectively: Userid content_id1:value1 content_id3:value2\n",
    "    * For example, for user 1000 (this is only a top-4 rec, list should contain 10-20),\n",
    "        * 100 1375666:1.420 0482571:0.232 1457767:0.158 1130884:0.113\n",
    "\n",
    "* Locate the recsys api template, where you should verify that the implementation will work with your implementation(/live-project/recs/non_negative_mf_recommender.py):\n",
    "    * In the __init__ method, check if the implementation can load your trained vectors.\n",
    "    * In the recommend_items method, return a recommendation for the user. Use the vectors loaded in the __init__ method.\n",
    "* Start the MovieGeek site.\n",
    "    * Find a user with a taste similar to yours by looking through users in the analytics part. This is user_id 100: http://0.0.0.0:8010/analytics/user/100/.\n",
    "    * Look at the recommendations your algorithm provides.\n",
    "* Write a report that describes\n",
    "    * how you implemented your algorithm\n",
    "    * how you trained the model\n",
    "    * what you think of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions prior to eval\n",
    "* I understand normalization when used for Feature Scaling; in the code you use Mean normalization with a plus 1 in the denominator, to coerce that matrix to be positive for the Non-negative matrix factorization. In the text, you say that normalized ratings makes them comparable. Could you elaborate on this? Is the idea of normalization to even out the effects of people who make different types of ratings, e.g.: one person gives ratings 1-5 while another person typically gives rating 4-9?\n",
    "\n",
    "* In the NMF example, how did you choose n_components=100? in the text you mention running SVD and selecting the number of columns that capture 90% of the sum of the Sigma matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* init='nndsvda' is excellent, but it averages across X; would it be better if each zero slot were filled by sampling from a distribution of that movies ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114508</td>\n",
       "      <td>8</td>\n",
       "      <td>2013-10-05 21:00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75314</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-23 01:42:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102926</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-22 11:46:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>114369</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-08-16 05:22:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>118715</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-07-29 07:13:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating    rating_timestamp\n",
       "0        1    114508       8 2013-10-05 21:00:50\n",
       "1        2     75314       1 2020-07-23 01:42:04\n",
       "2        2    102926       9 2020-05-22 11:46:56\n",
       "3        2    114369      10 2020-08-16 05:22:27\n",
       "4        2    118715       8 2020-07-29 07:13:18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data from https://github.com/sidooms/MovieTweetings\n",
    "# user_id::movie_id::rating::rating_timestamp. \n",
    "df = pd.read_csv(\"MovieTweetings-master/latest/ratings.dat\", \n",
    "                 sep=\"::\", engine=\"python\",\n",
    "                 names=[\"user_id\", \"movie_id\", \"rating\", \"rating_timestamp\"] )\n",
    "\n",
    "df['rating_timestamp'] = pd.to_datetime(df['rating_timestamp'], unit='s')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ratings made my users who have made more than one review: 858,457\n",
      "One review users: 29,995\n",
      "Number of distinct users with more than one review: 39,329\n"
     ]
    }
   ],
   "source": [
    "# drop all users who only rated 1 movie, they aren't helpful for recommendations;\n",
    "#  they can't be used to find similar items\n",
    "original_total = len(df)\n",
    "df = df.groupby(\"user_id\").filter(lambda x: len(x.movie_id) > 1)\n",
    "print(f\"Total number of ratings made my users who have made more than one review: {len(df):,}\")\n",
    "print(f\"One review users: {original_total - len(df):,}\")\n",
    "print(f\"Number of distinct users with more than one review: {len(set(df['user_id'].tolist())):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early attempt; cut out ratings from users with many\n",
    "# df100plus = df.groupby(\"user_id\").filter(lambda x: len(x.movie_id) >= 200) \n",
    "# df100plus['user_id'] = df100plus['user_id'].astype('category')\n",
    "# len(df100plus), len(set(df100plus['user_id'].tolist()))\n",
    "# 1701\n",
    "# df100plus['user_id'].unique() \n",
    "# df100plus[df100plus['user_id'] ==722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "strip_parens = re.compile(r\"\\s+\\(.*\\)\")\n",
    "text =\"In My Room (2020)\"\n",
    "# strip_parens.sub(\"\", text)\n",
    "def drop_parens(text):\n",
    "    return strip_parens.sub(\"\", text)\n",
    "def extract_year(text):\n",
    "    return text[text.rfind(\"(\") + 1 : text.rfind(\")\")]\n",
    "# extract_year(text)\n",
    "# extract_year('Remélem legközelebb sikerül meghalnod:) (2018)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze</td>\n",
       "      <td>1894</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>La sortie des usines Lumière</td>\n",
       "      <td>1895</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>The Arrival of a Train</td>\n",
       "      <td>1896</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "      <td>The Oxford and Cambridge University Boat Race</td>\n",
       "      <td>1895</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>Short|Horror</td>\n",
       "      <td>Le manoir du diable</td>\n",
       "      <td>1896</td>\n",
       "      <td>[Short, Horror]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id             genres                                          title  \\\n",
       "0         8  Documentary|Short         Edison Kinetoscopic Record of a Sneeze   \n",
       "1        10  Documentary|Short                   La sortie des usines Lumière   \n",
       "2        12  Documentary|Short                         The Arrival of a Train   \n",
       "3        25                     The Oxford and Cambridge University Boat Race   \n",
       "4        91       Short|Horror                            Le manoir du diable   \n",
       "\n",
       "   movie_year            genre_list  \n",
       "0        1894  [Documentary, Short]  \n",
       "1        1895  [Documentary, Short]  \n",
       "2        1896  [Documentary, Short]  \n",
       "3        1895                    []  \n",
       "4        1896       [Short, Horror]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movies.dat\n",
    "# Contains the items (i.e., movies) that were rated in the tweets,\n",
    "# together with their genre metadata in the following \n",
    "# format: movie_id::movie_title (movie_year)::genre|genre|genre. For example:\n",
    "\n",
    "# 0110912::Pulp Fiction (1994)::Crime|Thriller\n",
    "\n",
    "mdf = pd.read_csv(\"MovieTweetings-master/latest/movies.dat\", \n",
    "                 sep=\"::\", engine=\"python\",\n",
    "                 names=[\"movie_id\", \"movie_title\", \"genres\"] )\n",
    "mdf.genres.fillna(value='', inplace=True)\n",
    "mdf['title'] = mdf.movie_title.apply(drop_parens)\n",
    "mdf['movie_year'] = mdf.movie_title.apply(extract_year)\n",
    "mdf.movie_year = mdf.movie_year.astype('int')\n",
    "mdf['genre_list'] = mdf.genres.apply(lambda x: x.split(\"|\"))\n",
    "del mdf['movie_title']\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ids = list(sorted(set(rdf['user_id'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_ids = list(sorted(set(rdf['movie_id'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(movie_ids), movie_ids[-1])\n",
    "# first stab was: (36380, 12920708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_indices = dict(zip( movie_ids,   range(len(movie_ids)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr('raise')\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"Here we Mean normalize each of the users ratings against all their other ratings.\n",
    "    We plus 1 in the denomimator to coerce the matrix to be non-negative.\n",
    "    \"\"\"\n",
    "    x = x.astype(float)\n",
    "    x_sum = x.sum()\n",
    "    x_num = x.astype(bool).sum()\n",
    "    \n",
    "    if x_num == 1 or x.std() == 0 or x_sum == 0 or x_num == 0:\n",
    "        return 0.0\n",
    "    x_mean = x_sum / x_num\n",
    "    result = (x - x_mean) / (x.max() - x.min()) + 1 \n",
    "    # we add one so that non-negative numbers are passed to NMF\n",
    "    return result\n",
    "\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "\n",
    "# normalize the ratings?\n",
    "df['avg'] = df.groupby('user_id')['rating'].transform(lambda x: normalize(x))\n",
    "df['avg'] = df['avg'].astype(float)\n",
    "\n",
    "df['user_id'] = df['user_id'].astype('category')\n",
    "df['movie_id'] = df['movie_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train test sizes: 729,688,  128,769\n",
      "Train set size: 727,183 test set before trimming 128,769 \n",
      "test set size: 125,469\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=.15)\n",
    "\n",
    "print(f\"original train test sizes: {len(train):,},  {len(test):,}\") \n",
    "\n",
    "train = train.groupby(\"user_id\").filter(lambda x: len(x.movie_id) > 1)\n",
    "# test = test.groupby(\"user_id\").filter(lambda x: len(x.movie_id) > 1)\n",
    "print(f\"Train set size: {len(train):,} test set before trimming {len(test):,} \")\n",
    "\n",
    "test = test[test['user_id'].isin(train['user_id'].unique())]\n",
    "print(f\"test set size: {len(test):,}\")  \n",
    "\n",
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_timestamp</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508140</th>\n",
       "      <td>39980</td>\n",
       "      <td>1392190</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-23 14:15:52</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528410</th>\n",
       "      <td>41436</td>\n",
       "      <td>6966692</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-03-04 16:54:14</td>\n",
       "      <td>1.134683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583058</th>\n",
       "      <td>45641</td>\n",
       "      <td>4076916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-11-29 17:23:42</td>\n",
       "      <td>0.897181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633102</th>\n",
       "      <td>49577</td>\n",
       "      <td>1258972</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-03 12:59:09</td>\n",
       "      <td>0.748971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289053</th>\n",
       "      <td>22972</td>\n",
       "      <td>3001638</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014-09-06 17:29:53</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id movie_id  rating    rating_timestamp       avg\n",
       "508140   39980  1392190     5.0 2015-08-23 14:15:52  0.634921\n",
       "528410   41436  6966692     8.0 2019-03-04 16:54:14  1.134683\n",
       "583058   45641  4076916     4.0 2017-11-29 17:23:42  0.897181\n",
       "633102   49577  1258972     5.0 2015-08-03 12:59:09  0.748971\n",
       "289053   22972  3001638    10.0 2014-09-06 17:29:53  1.500000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_timestamp</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506866</th>\n",
       "      <td>39895</td>\n",
       "      <td>8579674</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020-02-13 14:36:40</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38527</th>\n",
       "      <td>2782</td>\n",
       "      <td>2239822</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-08-01 18:19:32</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266033</th>\n",
       "      <td>21097</td>\n",
       "      <td>2338151</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018-03-03 20:13:00</td>\n",
       "      <td>1.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650220</th>\n",
       "      <td>50719</td>\n",
       "      <td>1343092</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2014-04-06 17:48:16</td>\n",
       "      <td>1.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690906</th>\n",
       "      <td>54040</td>\n",
       "      <td>2388771</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-12-09 18:21:35</td>\n",
       "      <td>1.173611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550691</th>\n",
       "      <td>43101</td>\n",
       "      <td>1972779</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015-08-15 17:54:18</td>\n",
       "      <td>0.701266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180512</th>\n",
       "      <td>14207</td>\n",
       "      <td>2294449</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014-10-18 23:25:31</td>\n",
       "      <td>1.057613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590806</th>\n",
       "      <td>46353</td>\n",
       "      <td>2334896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-02-24 09:55:11</td>\n",
       "      <td>0.957965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757461</th>\n",
       "      <td>59521</td>\n",
       "      <td>110912</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013-04-08 05:58:53</td>\n",
       "      <td>1.192837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345425</th>\n",
       "      <td>27116</td>\n",
       "      <td>3369806</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-11-15 01:20:44</td>\n",
       "      <td>1.125828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140091</th>\n",
       "      <td>11077</td>\n",
       "      <td>1777034</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015-01-31 01:34:06</td>\n",
       "      <td>1.414634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696902</th>\n",
       "      <td>54540</td>\n",
       "      <td>2294629</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-12-15 03:45:21</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278913</th>\n",
       "      <td>21990</td>\n",
       "      <td>2184339</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2013-06-15 23:33:37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87514</th>\n",
       "      <td>6786</td>\n",
       "      <td>86393</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-04-14 21:31:14</td>\n",
       "      <td>0.740476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630500</th>\n",
       "      <td>49299</td>\n",
       "      <td>1023114</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-03-19 02:02:48</td>\n",
       "      <td>0.674797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855073</th>\n",
       "      <td>67211</td>\n",
       "      <td>2719848</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-11-07 23:09:19</td>\n",
       "      <td>1.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267853</th>\n",
       "      <td>21204</td>\n",
       "      <td>2386490</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-04-05 02:22:09</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251809</th>\n",
       "      <td>20099</td>\n",
       "      <td>1441395</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014-04-29 05:26:51</td>\n",
       "      <td>1.226601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464755</th>\n",
       "      <td>36474</td>\n",
       "      <td>3778644</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018-06-04 22:08:00</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439449</th>\n",
       "      <td>34268</td>\n",
       "      <td>1670345</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2014-07-26 20:39:21</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id movie_id  rating    rating_timestamp       avg\n",
       "506866   39895  8579674     7.0 2020-02-13 14:36:40  1.100000\n",
       "38527     2782  2239822     6.0 2017-08-01 18:19:32  0.583333\n",
       "266033   21097  2338151     8.0 2018-03-03 20:13:00  1.205128\n",
       "650220   50719  1343092     7.0 2014-04-06 17:48:16  1.004127\n",
       "690906   54040  2388771     9.0 2018-12-09 18:21:35  1.173611\n",
       "550691   43101  1972779     6.0 2015-08-15 17:54:18  0.701266\n",
       "180512   14207  2294449    10.0 2014-10-18 23:25:31  1.057613\n",
       "590806   46353  2334896     5.0 2014-02-24 09:55:11  0.957965\n",
       "757461   59521   110912     9.0 2013-04-08 05:58:53  1.192837\n",
       "345425   27116  3369806     7.0 2015-11-15 01:20:44  1.125828\n",
       "140091   11077  1777034    10.0 2015-01-31 01:34:06  1.414634\n",
       "696902   54540  2294629     7.0 2013-12-15 03:45:21  1.000000\n",
       "278913   21990  2184339    10.0 2013-06-15 23:33:37  0.000000\n",
       "87514     6786    86393     5.0 2016-04-14 21:31:14  0.740476\n",
       "630500   49299  1023114     5.0 2016-03-19 02:02:48  0.674797\n",
       "855073   67211  2719848     7.0 2015-11-07 23:09:19  1.064783\n",
       "267853   21204  2386490     6.0 2019-04-05 02:22:09  0.972222\n",
       "251809   20099  1441395     9.0 2014-04-29 05:26:51  1.226601\n",
       "464755   36474  3778644     6.0 2018-06-04 22:08:00  0.900000\n",
       "439449   34268  1670345     7.0 2014-07-26 20:39:21  0.571429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings are between 0.0 and 1.9090909090909083\n"
     ]
    }
   ],
   "source": [
    "coo = coo_matrix((df['avg'].astype(float), # was 'avg'\n",
    "                  (df['movie_id'].cat.codes.copy(), # rows\n",
    "                   df['user_id'].cat.codes.copy()))) # columns\n",
    "csr = coo.tocsr()\n",
    "print(f\"ratings are between {csr.asfptype().min()} and {csr.asfptype().max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumed = df.groupby(\"user_id\")['movie_id'].apply(list)\n",
    "\n",
    "def get_consumed_movies(inx):\n",
    "    return consumed.loc[inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = dict(enumerate(df['movie_id'].cat.categories))\n",
    "users = dict(enumerate(df['user_id'].cat.categories))\n",
    "\n",
    "users2inx = {v:k for k,v in users.items()}\n",
    "movie2inx = {v:k for k,v in movies.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=100, init='nndsvda', random_state=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.fit_transform(csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_recs(user_inx, take = 10):\n",
    "    user_vec = H[user_inx]\n",
    "    predictions = np.dot(user_vec, W.T)\n",
    "    top = np.argsort(predictions)[::-1][:(take * 2)]\n",
    "    return {movies.get(r, \"0\"): predictions[r] for r in top}\n",
    "\n",
    "def pred_rating(user_id, movie_id):\n",
    "    user_vec = H[users2inx[user_id]]\n",
    "    movie_vec = W[movie2inx[movie_id]]\n",
    "    return np.dot(user_vec, movie_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat =[]\n",
    "for idx, row in test.iterrows():\n",
    "    uid = row['user_id']\n",
    "    mid = row['movie_id']\n",
    "    yhat.append( pred_rating(uid, mid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892855886793963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test['avg'].tolist(), yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39329/39329 [02:10<00:00, 301.78it/s]\n"
     ]
    }
   ],
   "source": [
    "recs = [(user_id, predict_recs(inx)) for inx, user_id in tqdm(users.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_preds(row, user_inx=3):\n",
    "    result = []\n",
    "    for r in row:\n",
    "        user_vec = H[user_inx]\n",
    "        movie_vec = W[movie2inx[r]]\n",
    "        result.append(np.dot(user_vec, movie_vec))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/todd/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/todd/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_timestamp</th>\n",
       "      <th>avg</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>100</td>\n",
       "      <td>7286456</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-10-05 00:52:03</td>\n",
       "      <td>1.394636</td>\n",
       "      <td>1.412130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>100</td>\n",
       "      <td>6806448</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-08-09 04:06:49</td>\n",
       "      <td>0.950192</td>\n",
       "      <td>0.145258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>100</td>\n",
       "      <td>6105098</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-07-24 08:58:28</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.139432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>100</td>\n",
       "      <td>7349950</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-09-07 02:03:50</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.115530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>100</td>\n",
       "      <td>5164214</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-11-09 01:45:52</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.109325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>100</td>\n",
       "      <td>7798634</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-11-22 19:28:06</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.100432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>100</td>\n",
       "      <td>6450804</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-11-01 02:21:48</td>\n",
       "      <td>1.394636</td>\n",
       "      <td>0.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>100</td>\n",
       "      <td>3741700</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-06-09 18:40:18</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.071860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>100</td>\n",
       "      <td>8364368</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-07-12 00:53:47</td>\n",
       "      <td>1.283525</td>\n",
       "      <td>0.066279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>100</td>\n",
       "      <td>5606664</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-11-09 23:32:08</td>\n",
       "      <td>1.394636</td>\n",
       "      <td>0.064530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>100</td>\n",
       "      <td>3387520</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-08-31 01:03:50</td>\n",
       "      <td>0.950192</td>\n",
       "      <td>0.055652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>100</td>\n",
       "      <td>1025100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-10-19 05:07:26</td>\n",
       "      <td>0.616858</td>\n",
       "      <td>0.046781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>100</td>\n",
       "      <td>8350360</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-06-29 20:21:57</td>\n",
       "      <td>1.283525</td>\n",
       "      <td>0.045102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>100</td>\n",
       "      <td>8772262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-16 09:30:58</td>\n",
       "      <td>0.394636</td>\n",
       "      <td>0.035527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>100</td>\n",
       "      <td>2709692</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-08-07 17:24:08</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.031511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>100</td>\n",
       "      <td>5220122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-08-07 17:23:06</td>\n",
       "      <td>1.394636</td>\n",
       "      <td>0.030527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>100</td>\n",
       "      <td>6306064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-12-18 09:51:03</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.027822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>100</td>\n",
       "      <td>5638642</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-12-21 09:43:15</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.022118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>100</td>\n",
       "      <td>5113040</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-06-26 20:33:13</td>\n",
       "      <td>1.283525</td>\n",
       "      <td>0.020220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>100</td>\n",
       "      <td>5294518</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-11-30 14:54:03</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.014325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>100</td>\n",
       "      <td>5734576</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-04 04:40:32</td>\n",
       "      <td>0.616858</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>100</td>\n",
       "      <td>9541602</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-12-18 09:52:13</td>\n",
       "      <td>0.950192</td>\n",
       "      <td>0.006414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>100</td>\n",
       "      <td>6423362</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-12-17 07:02:32</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.005161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>100</td>\n",
       "      <td>10648440</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-09-28 21:40:42</td>\n",
       "      <td>1.172414</td>\n",
       "      <td>0.005048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>100</td>\n",
       "      <td>1259521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-06-15 15:23:47</td>\n",
       "      <td>0.394636</td>\n",
       "      <td>0.004180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>100</td>\n",
       "      <td>8267604</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-03-04 04:31:22</td>\n",
       "      <td>1.394636</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>100</td>\n",
       "      <td>9086228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-02-01 02:45:12</td>\n",
       "      <td>0.394636</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>100</td>\n",
       "      <td>7535964</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-12-23 11:07:15</td>\n",
       "      <td>1.172414</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>100</td>\n",
       "      <td>7022402</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-12-17 05:13:49</td>\n",
       "      <td>1.061303</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  movie_id  rating    rating_timestamp       avg  predictions\n",
       "1287     100   7286456    10.0 2019-10-05 00:52:03  1.394636     1.412130\n",
       "1285     100   6806448     6.0 2019-08-09 04:06:49  0.950192     0.145258\n",
       "1281     100   6105098     5.0 2019-07-24 08:58:28  0.839080     0.139432\n",
       "1288     100   7349950     7.0 2019-09-07 02:03:50  1.061303     0.115530\n",
       "1275     100   5164214     7.0 2019-11-09 01:45:52  1.061303     0.109325\n",
       "1290     100   7798634     7.0 2019-11-22 19:28:06  1.061303     0.100432\n",
       "1284     100   6450804    10.0 2019-11-01 02:21:48  1.394636     0.073968\n",
       "1273     100   3741700     7.0 2019-06-09 18:40:18  1.061303     0.071860\n",
       "1293     100   8364368     9.0 2019-07-12 00:53:47  1.283525     0.066279\n",
       "1278     100   5606664    10.0 2019-11-09 23:32:08  1.394636     0.064530\n",
       "1272     100   3387520     6.0 2019-08-31 01:03:50  0.950192     0.055652\n",
       "1268     100   1025100     3.0 2019-10-19 05:07:26  0.616858     0.046781\n",
       "1292     100   8350360     9.0 2019-06-29 20:21:57  1.283525     0.045102\n",
       "1294     100   8772262     1.0 2019-12-16 09:30:58  0.394636     0.035527\n",
       "1271     100   2709692     7.0 2019-08-07 17:24:08  1.061303     0.031511\n",
       "1276     100   5220122    10.0 2019-08-07 17:23:06  1.394636     0.030527\n",
       "1282     100   6306064     4.0 2019-12-18 09:51:03  0.727969     0.027822\n",
       "1279     100   5638642     5.0 2019-12-21 09:43:15  0.839080     0.022118\n",
       "1274     100   5113040     9.0 2019-06-26 20:33:13  1.283525     0.020220\n",
       "1277     100   5294518     7.0 2019-11-30 14:54:03  1.061303     0.014325\n",
       "1280     100   5734576     3.0 2019-03-04 04:40:32  0.616858     0.007685\n",
       "1296     100   9541602     6.0 2019-12-18 09:52:13  0.950192     0.006414\n",
       "1283     100   6423362     4.0 2019-12-17 07:02:32  0.727969     0.005161\n",
       "1269     100  10648440     8.0 2019-09-28 21:40:42  1.172414     0.005048\n",
       "1270     100   1259521     1.0 2019-06-15 15:23:47  0.394636     0.004180\n",
       "1291     100   8267604    10.0 2019-03-04 04:31:22  1.394636     0.002738\n",
       "1295     100   9086228     1.0 2020-02-01 02:45:12  0.394636     0.001246\n",
       "1289     100   7535964     8.0 2019-12-23 11:07:15  1.172414     0.000811\n",
       "1286     100   7022402     7.0 2019-12-17 05:13:49  1.061303     0.000363"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_ratings_predictions(user_id):\n",
    "    \n",
    "    user_x = df.loc[(df['user_id'] == user_id)]\n",
    "\n",
    "    user_x.loc[:, \"predictions\"] = lookup_preds(user_x['movie_id'], users2inx[user_id])\n",
    "    return user_x.sort_values('predictions', ascending=False)\n",
    "\n",
    "compare_ratings_predictions(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39329/39329 [00:01<00:00, 19774.32it/s]\n"
     ]
    }
   ],
   "source": [
    "save_path = \"nnmf_recs.csv\"\n",
    "import csv\n",
    "with open(save_path, 'w', newline='') as csvfile:\n",
    "    rec_writer = csv.writer(csvfile, delimiter=' ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for rec in tqdm(recs):\n",
    "        rec_writer.writerow([rec[0]] + ['{}:{}'.format(k,v) for k,v in rec[1].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
